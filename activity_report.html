<!DOCTYPE html>
<html lang="ja">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="http://anshun9.jc.fit.ac.jp/zemi/">
    <meta property="og:image" content="https://ferret-plus.com/images/logo.jpg">
    <meta property="og:site_name" content="曽研究室 情報科学研究セミナー" />
    <meta property="og:description" content="福岡工業大学短期大学部　曽研究室の活動記録を掲載しています" />
    <link rel="stylesheet" href="https://fonts.googleapis.com/earlyaccess/notosansjp.css">
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm"
    crossorigin="anonymous">
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
    crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
    crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
    crossorigin="anonymous"></script>
    <script src="https://use.typekit.net/lpb0xra.js"></script>
    <script>try { Typekit.load({ async: true }); } catch (e) { }</script>
    <title>曽研究室 アクティビティレポート</title>
    <style media="screen">
    * {
      font-family: 'Noto Sans JP';
    }

    h1 {
      text-align: center;
      margin: 5vh 0;
      font-size: 3.5vh;
    }
    header h1{
      font-size: 5vh;
    }
    .article h1{
      font-size: 2.75vh;
    }
    h2 {
      text-align: center;
      font-size: 3.5vh;
    }

    p {
      margin: 3vh auto;
      text-align: center;
    }

    @media (max-width: 780px) {
      h1 {
        font-size: 1.5rem;
      }
      .textblock {
        display: inline;
      }
      p {
        text-align: left;
      }
    }

    html>body {
      margin: 0 10vw;
      background: linear-gradient(47deg, #93e6e0, #ce9df0, #b4f09d);
      background-size: 600% 600%;
      animation: backgroundgradient 18s ease infinite;
    }

    @keyframes backgroundgradient {
      0% {
        background-position: 0% 78%
      }
      50% {
        background-position: 100% 23%
      }
      100% {
        background-position: 0% 78%
      }
    }

    section {
      margin: 10vh 0;
    }

    .textblock {
      display: inline-block;
    }

    table, .article {
      margin: 0 auto;
      background-color: rgba(255, 255, 255, 0.25) !important;
    }

    table tr {
      line-height: 2em;
    }

    table td {
      padding-left: 2vw;
    }
    </style>
  </head>


  <body>
    <header>
      <h1 id="title">曽研究室 アクティビティレポート</h1>
    </header>

    <!--<nav>

    </nav>-->

    <section>
      <h1>記事一覧</h1>
      <table>
        <!--
        <tr>
          <th>2018.3.9</th>
          <td>第2回 情報科学研究セミナー を開催しました</td>
        </tr>
        -->
        <tr>
          <a href="#event_20180316">
            <th>2018.3.16</th>
            <td>LINE Developer Meetup #29 ー LINE Bot開発（福岡）に参加してきました！</td>
          </a>
        </tr>

        <tr>
          <a href="#event_20180315">
            <th>2018.3.15</th>
            <td>DLLAB Academy: Chainerで学ぶ深層学習入門（福岡）に参加してきました！</td>
          </a>
        </tr>

        <tr>
          <a href="#zemi_02">
            <th>2018.3.9</th>
            <td>第2回 情報科学研究セミナー を開催しました</td>
          </a>
        </tr>

        <tr>
          <a href="#event_20180303">
            <th>2018.3.3</th>
            <td>Atack & Defence in Fukuoka #2 に参加してきました！</td>
          </a>
        </tr>

        <tr>
          <a href="#zemi_01">
            <th>2018.2.22</th>
            <td>第1回 情報科学研究セミナー を開催しました</td>
          </a>
        </tr>

        <tr>
          <a href="#event_20180217">
            <th>2018.2.17</th>
            <td>Hacker Tackle 2018 に参加してきました！</td>
          </a>
        </tr>

        <tr>
          <th>2018.2.28</th>
          <td>本ページを公開しました</td>
        </tr>
      </table>
    </section>

    <section class="article" id="event_20180315">
        <h1>DLLAB Academy: Chainerで学ぶ深層学習入門（福岡）に参加してきました！</h1>
        <h4>概要</h4>
        <p style="line-height:2em;">
          機械学習のフレームワーク「Chainer」を開発しているPreffered Network社とマイクロソフト社らで構成されたDeep Learning LABが主催する3日間有償コースのお試し4時間無償セミナーを受講して来ました。
        </p>
        <p style="text-align:left;line-height:2em;">
          &nbsp全体として、深層学習の基礎となる機械学習やニューラルネットワークの基礎にフォーカスした内容で、冒頭に機械学習やニューラルネットワークの概念や用語について解説がありました。
          &nbspその後、ニューラルネットワークと数学の関係紙の上で手計算で一つ一つ追っていき、白ワインと赤ワインの分類や家賃の予測の例題を通してプログラム内部で行われている計算処理を確認していきました。
          &nbspこの部分で時間の大半を費やしたため、機械学習フレームワーク Chainer を使ったプログラミングについてはほとんどコピペで行い、デモプログラムを走らせてとりあえず流れは一通り見たという形で終わりました。
        </p>
        <h4>ノート</h4>
        <p>
          <ul>
            <li>深層学習の位置付け：人工知能　＞　機械学習　＞　ニューラルネットワーク　＞　深層学習（ディープラーニング）</li>
            <br>
            <li>深層学習の主な応用分野</li>
            <br>
            <table class="table table-sm table-striped table-bordered" style="max-width:50%">
              <thead>
                <tr>
                  <th>応用分野</th>
                  <th>人間における部位</th>
                  <th>要素・基準</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>画像処理</td>
                  <td>目</td>
                  <td>光の強さ、色</td>
                </tr>
                <tr>
                  <td>音声処理</td>
                  <td>耳</td>
                  <td>空気の振動</td>
                </tr>
                <tr>
                  <td>画像処理</td>
                  <td>口</td>
                  <td>特徴量</td>
                </tr>
              </tbody>
            </table>
            <li>機械学習に必要な数学</li>
            <br>
            <ul>
              <li>微分・積分</li>
              <li>線形代数</li>
              <li>確率・統計</li>
            </ul>
            <br>
            <li>学習と推論</li>
            <br>
            <table class="table table-sm table-striped table-bordered" style="max-width:50%">
              <thead>
                <tr>
                  <th style="width:4em"></th>
                  <th>説明</th>
                  <th>登場人物</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <th>学習</th>
                  <td>入力変数と出力変数を結びつけること</td>
                  <td>入力変数x と 目的変数t</td>
                </tr>
                <tr>
                  <th>推論</th>
                  <td>入力変数をもとに予測値を出力していく</td>
                  <td>入力変数x と 出力変数y</td>
                </tr>
              </tbody>
            </table>
            <li>ニューラルネットワークにおける２つのアプローチ法</li>
            <br>
            <ul>
              <li>回帰：ある条件における予測値を求める</li>
              <li>分類：あらかじめ設定した分類において、クラスに属する確率</li>
            </ul>
            <br>
            <li>ニューラルネットワークの構造</li>
            <br>
            <ul>
              <li>ノード：ニューロンを図式化したもの</li>
              <li>接続：ノード間をつなぐ樹状突起を図式化したもの</li>
              <li>入力変数(x)：判断するためのファクターのこと</li>
              <li>出力変数(y)：回帰では予測値、分類では各分類の実態を表す</li>
              <li>教師データ：学習の段階で利用する、入力変数と出力されるべき値（目的変数(t)）のセット</li>
              <li>入力層：入力ノード（変数）をまとめて表現したもの</li>
              <li>出力層：出力ノード（変数）をまとめて表現したもの</li>
              <li>中間（隠れ）層：入力層と出力層の間にある層</li>
              <li>パラメータ：調整すべき値</li>
              <ul>
                <li>重み(w)：各接続（ノード間）に与える重要度を数値化したもの、初期値はランダムに与えられる</li>
                <li>バイアス(b)：各接続（ノード間）に与える重要度において、重みだけで表現できない部分を数値化したもの</li>
              </ul>
              <li>損失関数：学習の段階において、目的変数と出力変数にどれだけ誤差があるかを求める関数。パラメーターの更新に利用される。</li>
              <li>モデル化（定式化）（※ 入力ノード数3, 出力ノード数2の2層NNと仮定）</li>
              <br>
              <ol>
                <li>x(入力層)からu(次の層)までの線形変換
                  <img src="https://chart.googleapis.com/chart?cht=tx&chl=u_1=w_{11}x_1%2Bw_{12}x_2%2Bw_{13}x_3%2Bb_1,\ \\ u_2=w_{21}x_1%2Bw_{22}x_2%2Bw_{23}x_3%2Bb_2&chco=000000&chf=bg,s,65432100">
                  (w:重み, b:バイアス)
                </li>
                <br>
                <li>u(受け取って線形変換した値)からz(次の層に伝える値)への非線形変換</li>
                <br>
                <ul>
                  <li>シグモイド関数：あらゆる値を０〜１の間の値に変換する。深層学習において情報の消失問題が指摘されている。</li>
                  <li>Relu関数：負の値は０に、正の値はそのままの値を出力する関数。現在の主流。</li>
                </ul>

              </ol>
            </ul>
            <br>
            <li>ニューラルネットワークの計算手順</li>
            <br>
            <ol>
              <li>予測を行う判断材料（要素）を検討し、それらを数値化しておく　←　ここ重要</li>
              <li>パラメータ（重み、バイアス）をランダムにセット</li>
              <li>入力変数と目的変数のセットを用意</li>
              <li>前段階でセットした入力変数とパラメーターを用いてニューラルネットワークで計算し、出力変数を得る</li>
              <li>損失関数を用いて出力変数と目的変数の誤差を計算し、それを基にパラメーターを調整・最適化を行う</li>
            </ol>
            <br>
            <li>順伝播と逆伝播</li>
            <br>
            <ul>
              <li>順伝播：実際に計算して誤差を取ること</li>
              <li>逆伝播：順伝播で得た誤差に基づいてパラメーターを調整すること</li>
              <br>
              この順伝播と逆伝播を何度も繰り返すことが学習のプロセス
            </ul>
            <br>
            <li>Chainer について</li>
            <br>
            <ul>
              <li>国産の機械学習フレームワーク</li>
              <li>"Define by Run"というポリシーの基、デバッグのしやすさや計算プロセス把握の容易さを売りにしている</li>
            </ul>
          </ul>
          <h4>手書き資料</h4>
          <object data="./pdf/event_20180315.pdf#view=Fit" type="application/pdf" height="500" width="50%" style="margin-left:25%;">
            <iframe src="./pdf/event_20180315.pdf" width="25%">
              <p><a href="./pdf/event_20180315.pdf">PDF資料をダウンロード</a></p>
            </iframe>
          </object>



        </p>
        <!--<img src="https://chart.googleapis.com/chart?cht=tx&chl=x^2%2B1&chco=ff0000&chf=bg,s,65432100">-->
        <dl class="">
          <dt>開催日</dt>
          <dd>2018.3.15 - Wed</dd>
          <dt>参加者</dt>
          <dd>東　昭太朗</dd>
          <dt>開催地</dt>
          <dd>マイクロソフト九州支社</dd>
        </dl>
    </section>

    <!--<section class="article" id="event_20180217">
        <h1>Hacker Tackle 2018 に参加してきました！</h1>
        <h4>概要</h4>
        <p style="line-height:2em;">
          機械学習のフレームワーク「Chainer」を開発しているPreffered Network社とマイクロソフト社らで構成されたDeep Learning LABが主催する3日間有償コースのお試し4時間無償セミナーを受講して来ました。
        </p>
        <p style="text-align:left;line-height:2em;">
          &nbsp全体として、深層学習の基礎となる機械学習やニューラルネットワークの基礎にフォーカスした内容で、冒頭に機械学習やニューラルネットワークの概念や用語について解説がありました。
          &nbspその後、ニューラルネットワークと数学の関係紙の上で手計算で一つ一つ追っていき、白ワインと赤ワインの分類や家賃の予測の例題を通してプログラム内部で行われている計算処理を確認していきました。
          &nbspこの部分で時間の大半を費やしたため、機械学習フレームワーク Chainer を使ったプログラミングについてはほとんどコピペで行い、デモプログラムを走らせてとりあえず流れは一通り見たという形で終わりました。
        </p>
        <h4>ノート</h4>
        <p>

        </p>
        <dl class="">
          <dt>開催日</dt>
          <dd>2018.2.17</dd>
          <dt>参加者</dt>
          <dd>東　昭太朗, 渕上　朔太郎</dd>
          <dt>開催地</dt>
          <dd>株式会社 LINE Fukuoka</dd>
        </dl>
    </section>-->
  </body>

</html>
